---
title: "CSE 160 Final Project"
author:
  - Hamza Ali
  - Wajid Ashraf
  - Jeremy Learner
  - Buckley Ross
  - Tyler Waldvogel
date: "11/29/2021"
output: html_document
---


## R Markdown

```{r}
library(ggplot2)
data_raw <- read.csv("movies_metadata.csv")
data_raw <- data_raw[data_raw$status=="Released",]
data <- data_raw[data_raw$vote_count>800,-c(1, 6, 7, 9, 10, 12, 18, 19, 20, 22)]
data <- data[data$revenue>0,]
data <- data[data$budget>1000,]
data$popularity <- as.double(data$popularity)
data$budget <- as.double(data$budget)
data$belongs_to_collection <- !(data$belongs_to_collection=="")
data$homepage <- !(data$homepage == "")
data$genres <- gsub("[[:space:]]", "", data$genres)

data$Action <- grepl('Action', data$genres, fixed = TRUE); data$Adventure <- grepl('Adventure', data$genres, fixed = TRUE); data$Animation <- grepl('Animation', data$genres, fixed = TRUE); data$Comedy <- grepl('Comedy', data$genres, fixed = TRUE); data$Crime <- grepl('Crime', data$genres, fixed = TRUE); data$Drama <- grepl('Drama', data$genres, fixed = TRUE); data$Family <- grepl('Family', data$genres, fixed = TRUE); data$Fantasy <- grepl('Fantasy', data$genres, fixed = TRUE); data$History <- grepl('History', data$genres, fixed = TRUE); data$Horror <- grepl('Horror', data$genres, fixed = TRUE); data$Music <- grepl('Music', data$genres, fixed = TRUE); data$Mystery <- grepl('Mystery', data$genres, fixed = TRUE); data$Romance <- grepl('Romance', data$genres, fixed = TRUE); data$Science_Fiction <- grepl('ScienceFiction', data$genres, fixed = TRUE); data$Thriller <- grepl('Thriller', data$genres, fixed = TRUE); data$War <- grepl('War', data$genres, fixed = TRUE); data$Western <- grepl('Western', data$genres, fixed = TRUE);
data <- data[,-c(3,6,7,8)]

data$release_date <- as.Date(data$release_date)
data$year = as.numeric(format(data$release_date, format = "%Y"));
data$month = as.numeric(format(data$release_date, format = "%m"));
data$day = as.numeric(format(data$release_date, format = "%d"));

data$ratio <- (data$revenue/data$budget)
data$is_successful <- (data$ratio > 4)
data$is_English <- data$original_language == "en"
data <- data[,-c(4,9)]
```
Ten Fold Cross Validation:
```{r}
library(e1071)
#make matrix to store values
recall_totals <- 0
precision_totals <- 0
accuracy_totals <- 0
fMeasure_totals <- 0

#10-fold validation using Naive Bayes
for (i in 1:10) {
  m <- dim(data)[1]
  foldLength <- round(m/10) # Create 10 folds
  val <- c(1:foldLength) + foldLength*(i-1)
  if (i == 10) {
    val <- c(m-foldLength:m)
  }
  trainData <- data[-val, ]
  testData <- data[val, ]
    
#use naive bayes to create classifier model
  nb <- naiveBayes(is_successful~budget+vote_count+ratio, data = trainData)
  pred <- predict(nb, newdata = testData, type = 'raw')
  pred <- ifelse(pred > 0.5, 1, 0)
  tab <- table(testData$is_successful, pred)
  tab
#define true and false positives and negatives
  TP <- tab[1,1]
  FP <- tab[1,2]
  FN <- tab[2,1]
  TN <- tab[2,2]
    
#calculate precision, recall, accuracy, and f-measure respectively, for the fold
  precision <- TP/(TP+FP)
  precision_totals <- precision_totals + precision
    
  recall <- TP/(TP+FN)
  recall_totals <- recall_totals + recall
   
  accuracy <- (TP+TN)/(TP+TN+FP+FN)
  accuracy_totals <- accuracy_totals + accuracy

  fMeasure <- 2 * precision * recall / (precision + recall)
  fMeasure_totals <- fMeasure_totals + fMeasure
}

#Average measures and print
cat("\nAverage Accuracy:\n")
accuracy_totals/10
cat("\nAverage Precision:\n")
precision_totals/10
cat("\nAverage Recall:\n")
recall_totals/10
cat("\nAverage f-Measure:\n")
fMeasure_totals/10
```

```{r}
library(caTools)
library(ROCR)
library(e1071)

split <- sample(2, nrow(data), replace = TRUE, prob = c(.8, .2))
trainData <- data[split == 1,]
testData <- data[split == 2,]
#NB
nb <- naiveBayes(formula = as.factor(is_successful) ~ budget+homepage+runtime+is_English+vote_average+belongs_to_collection, data = trainData)

pNB <- predict(nb, newdata = testData, type = 'raw')
table(data.frame(testData$is_successful, pNB > 0.5))
curveNB <- prediction(pNB[,2], testData$is_successful)
performanceNB <- performance(curveNB, 'tpr', 'fpr')
regressionModel <- glm(is_successful ~ Action+Adventure+Animation+Comedy+Crime+Drama+Family+Fantasy+History+Horror+Music+Mystery+Romance+Science_Fiction+Thriller+War+Western, data = trainData, family = "binomial")

pred <- predict(regressionModel, testData, type = "response")
t <-table(data.frame(testData$is_successful, pred > .5))

curveLR <- prediction(pred, testData$is_successful)
performanceLR <- performance(curveLR, 'tpr', 'fpr')
plot(performanceNB, col = 1, main = "ROC")
plot(performanceLR, col = 2, add = T)
legend(.6,.3,c('Naive Bayes', 'Logistic Regression'), 1:2)

```


## Including Plots

You can also embed plots, for example:

```{r}
library(ggplot2)
revenuemodel <- lm(revenue~budget+vote_count,data = data)

summary(revenuemodel) #chose those variables because they had the highest r squared
plot(revenuemodel)


genres1 <-c(mean(data$ratio[data$Action==TRUE]), mean(data$ratio[data$Adventure==TRUE]), mean(data$ratio[data$Animation==TRUE]), mean(data$ratio[data$Comedy==TRUE]), mean(data$ratio[data$Crime==TRUE]), mean(data$ratio[data$Drama==TRUE]), mean(data$ratio[data$Family==TRUE]), mean(data$ratio[data$Fantasy==TRUE]), mean(data$ratio[data$History==TRUE]), mean(data$ratio[data$Horror==TRUE]), mean(data$ratio[data$Music==TRUE]), mean(data$ratio[data$Mystery==TRUE]), mean(data$ratio[data$Romance==TRUE]), mean(data$ratio[data$Science_Fiction==TRUE]), mean(data$ratio[data$Thriller==TRUE]),mean(data$ratio[data$War==TRUE]), mean(data$ratio[data$War==TRUE]), mean(data$ratio[data$Western==TRUE]))
p<-ggplot(data=data, aes(x=genres1, y=revenue)) +
  geom_bar(stat="identity")
#p
en <- length(data$original_language[data$original_language=="en"])
en <- (en/1344)*100


b <- table(data$original_language)

b <- 100 * b/nrow(data)
b
group <- unique((data$original_language))
group
ggplot(data, aes(x="", y=original_language, fill=group)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  
  theme_void() # remove background, grid, numeric labels

success<-ggplot(data=data, aes(x=is_successful, y=frequency(is_successful) , fill = is_successful)) +
  geom_bar(stat="identity") +
xlab("Is Succesful") + 
    ylab("# of Movies")                 +
    ggtitle("Number of Movies that are Successful ") 
success
```

Random Forest
```{r}
library(randomForest)
library(rpart)
library(rpart.plot)
library(caret)
#set.seed(4567)
split <- sample(2, nrow(data), replace = TRUE, prob = c(.8, .2))
trainData <- data[split == 1,]
testData <- data[split == 2,]
tree <- rpart(is_successful~month+budget+vote_average+belongs_to_collection+homepage+runtime, data = trainData, method = "class")
prp(tree)
# build decision forest
forest <- randomForest(is_successful~budget+ratio+vote_average+belongs_to_collection+homepage+runtime, data = trainData, importance = TRUE, ntree = 1000)
# plots regression


#evaluate tree and forest on training data
tree.train <- predict(tree, newdata=testData, type="class")
forest.train <- predict(forest, newdata=testData, type="class")
#confusionMatrix(forest.train, testData$is_successful)

table.traintree <- table(tree.train, testData$is_successful)
table.trainforest <- table(forest.train, testData$is_successful)

#calculate accuracies
accuracy.traintree = sum(diag(table.traintree))/sum(table.traintree) 
accuracy.trainforest = sum(diag(table.trainforest))/sum(table.trainforest) 

cat("Tree training accuracy: ", accuracy.traintree, "\n")
cat("Forest training accuracy: ", accuracy.trainforest, "\n")
```

Ten Fold Cross Validation:
```{r}
library(e1071)
#make matrix to store values
recall_totals <- 0
precision_totals <- 0
accuracy_totals <- 0
fMeasure_totals <- 0

#10-fold validation using Naive Bayes
for (i in 1:10) {
  m <- dim(data)[1]
  foldLength <- round(m/10) # Create 10 folds
  val <- c(1:foldLength) + foldLength*(i-1)
  if (i == 10) {
    val <- c(m-foldLength:m)
  }
  trainData <- data[-val, ]
  testData <- data[val, ]
    
#use naive bayes to create classifier model
  nb <- naiveBayes(is_successful~budget+vote_count+ratio, data = trainData)
  pred <- predict(nb, newdata = testData, type = 'raw')
  pred <- ifelse(pred > 0.5, 1, 0)
  tab <- table(testData$is_successful, pred)
  tab
#define true and false positives and negatives
  TP <- tab[1,1]
  FP <- tab[1,2]
  FN <- tab[2,1]
  TN <- tab[2,2]
    
#calculate precision, recall, accuracy, and f-measure respectively, for the fold
  precision <- TP/(TP+FP)
  precision_totals <- precision_totals + precision
    
  recall <- TP/(TP+FN)
  recall_totals <- recall_totals + recall
   
  accuracy <- (TP+TN)/(TP+TN+FP+FN)
  accuracy_totals <- accuracy_totals + accuracy

  fMeasure <- 2 * precision * recall / (precision + recall)
  fMeasure_totals <- fMeasure_totals + fMeasure
}

#Average measures and print
cat("\nAverage Accuracy:\n")
accuracy_totals/10
cat("\nAverage Precision:\n")
precision_totals/10
cat("\nAverage Recall:\n")
recall_totals/10
cat("\nAverage f-Measure:\n")
fMeasure_totals/10



```
Random Forest
```{r}
library(randomForest)
library(rpart)

tree <- rpart(revenue~budget+popularity+vote_count, data = data, method = "class")

# build decision forest
forest <- randomForest(revenue~budget+popularity+vote_count, data = data, importance = TRUE, ntree = 1000, na.action=na.roughfix)
# plots regression
# varImpPlot(my_forest)


#evaluate tree and forest on training data
tree.train <- predict(tree, newdata=train, type="class")
forest.train <- predict(forest, newdata=train)

table.traintree <- table(tree.train, train$survived)
table.trainforest <- table(forest.train, train$survived)

#calculate accuracies
accuracy.traintree = sum(diag(table.traintree))/sum(table.traintree) 
accuracy.trainforest = sum(diag(table.trainforest))/sum(table.trainforest) 

cat("Tree training accuracy: ", accuracy.traintree, "\n")
cat("Forest training accuracy: ", accuracy.trainforest, "\n")
```

```{r}
library(randomForest)
library(caret)
library(ggplot2)
library(plotROC)
```
```{r}
#10 folds repeat 3 times
#control <- trainControl(method='repeatedcv', number=10, repeats=3)
control <- trainControl(method='cv', number=10, summaryFunction=twoClassSummary, classProbs=T, savePredictions=T)

# Generate the model:
data$success <- as.factor(data$is_successful)
levels(data$success) <- c("bad", "good")
model <- train(success ~ budget + is_English + release_date + runtime + belongs_to_collection, 
    data=data,
    method='rf',
    trControl=control)
print(model)
```
```{r}
ggplot(model$pred, aes(m=good, d =obs)) + 
  geom_roc(hjust = -0.4, vjust = 1.5) +
  coord_equal() +
  geom_abline(slope=1, intercept=c(0,0)) +
  theme(title=element_text("ROC Curve of Random Forest Algorithm")) +
  labs(x="False Positives", y="True Positives")
```
