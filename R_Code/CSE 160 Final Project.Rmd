---
title: "CSE 160 Final Project"
author:
  - Hamza Ali
  - Wajid Ashraf
  - Jeremy Learner
  - Buckley Ross
  - Tyler Waldvogel
date: "11/29/2021"
output: html_document
---


## R Markdown

```{r}
data_raw <- read.csv("movies_metadata.csv")
data_raw <- data_raw[data_raw$status=="Released",]
data <- data_raw[data_raw$vote_count>800,-c(1, 6, 7, 9, 10, 12, 18, 19, 20, 22)]
data <- data[data$revenue>0,]
data <- data[data$budget>1000,]
data$popularity <- as.double(data$popularity)
data$budget <- as.double(data$budget)
data$belongs_to_collection <- !(data$belongs_to_collection=="")
data$homepage <- !(data$homepage == "")
data$genres <- gsub("[[:space:]]", "", data$genres)

data$Action <- grepl('Action', data$genres, fixed = TRUE); data$Adventure <- grepl('Adventure', data$genres, fixed = TRUE); data$Animation <- grepl('Animation', data$genres, fixed = TRUE); data$Comedy <- grepl('Comedy', data$genres, fixed = TRUE); data$Crime <- grepl('Crime', data$genres, fixed = TRUE); data$Drama <- grepl('Drama', data$genres, fixed = TRUE); data$Family <- grepl('Family', data$genres, fixed = TRUE); data$Fantasy <- grepl('Fantasy', data$genres, fixed = TRUE); data$History <- grepl('History', data$genres, fixed = TRUE); data$Horror <- grepl('Horror', data$genres, fixed = TRUE); data$Music <- grepl('Music', data$genres, fixed = TRUE); data$Mystery <- grepl('Mystery', data$genres, fixed = TRUE); data$Romance <- grepl('Romance', data$genres, fixed = TRUE); data$Science_Fiction <- grepl('ScienceFiction', data$genres, fixed = TRUE); data$Thriller <- grepl('Thriller', data$genres, fixed = TRUE); data$War <- grepl('War', data$genres, fixed = TRUE); data$Western <- grepl('Western', data$genres, fixed = TRUE);
data <- data[,-c(3,6,7,8)]

data$release_date <- as.Date(data$release_date)
data$year = as.numeric(format(data$release_date, format = "%Y"));
data$month = as.numeric(format(data$release_date, format = "%m"));
data$day = as.numeric(format(data$release_date, format = "%d"));

data$ratio <- (data$revenue/data$budget)
data$is_successful <- (data$ratio > 4)

data$is_English <- data$original_language == "en"
data <- data[,-c(4,9)]
```
Ten Fold Cross Validation:
```{r}
library(e1071)
#make matrix to store values
recall_totals <- 0
precision_totals <- 0
accuracy_totals <- 0
fMeasure_totals <- 0

#10-fold validation using Naive Bayes
for (i in 1:10) {
  m <- dim(data)[1]
  foldLength <- round(m/10) # Create 10 folds
  val <- c(1:foldLength) + foldLength*(i-1)
  if (i == 10) {
    val <- c(m-foldLength:m)
  }
  trainData <- data[-val, ]
  testData <- data[val, ]
    
#use naive bayes to create classifier model
  nb <- naiveBayes(is_successful~budget+vote_count+ratio, data = trainData)
  pred <- predict(nb, newdata = testData, type = 'raw')
  pred <- ifelse(pred > 0.5, 1, 0)
  tab <- table(testData$is_successful, pred)
  tab
#define true and false positives and negatives
  TP <- tab[1,1]
  FP <- tab[1,2]
  FN <- tab[2,1]
  TN <- tab[2,2]
    
#calculate precision, recall, accuracy, and f-measure respectively, for the fold
  precision <- TP/(TP+FP)
  precision_totals <- precision_totals + precision
    
  recall <- TP/(TP+FN)
  recall_totals <- recall_totals + recall
   
  accuracy <- (TP+TN)/(TP+TN+FP+FN)
  accuracy_totals <- accuracy_totals + accuracy

  fMeasure <- 2 * precision * recall / (precision + recall)
  fMeasure_totals <- fMeasure_totals + fMeasure
}

#Average measures and print
cat("\nAverage Accuracy:\n")
accuracy_totals/10
cat("\nAverage Precision:\n")
precision_totals/10
cat("\nAverage Recall:\n")
recall_totals/10
cat("\nAverage f-Measure:\n")
fMeasure_totals/10



```

```{r}
library(caTools)
library(ROCR)
library(e1071)

data$Class <- replace(data$Class, 2, 0)
data$Class <- replace(data$Class, 4, 1)

split <- sample(2, nrow(data), replace = TRUE, prob = c(.8, .2))
trainData <- data[split == 1,]
testData <- data[split == 2,]
#NB
nb <- naiveBayes(formula = as.factor(Class) ~., data = trainData)
pNB <- predict(nb, newdata = testData, type = 'raw')
curveNB <- prediction(pNB[,2], testData$Class)
performanceNB <- performance(curveNB, 'tpr', 'fpr')
regressionModel <- glm(Class ~ ., data = trainData, family = "binomial")
pred <- predict(regressionModel, testData, type = "response")
t <-table(data.frame(testData$Class, pred > .5))
curveLR <- prediction(pred, testData$Class)
performanceLR <- performance(curveLR, 'tpr', 'fpr')
plot(performanceNB, col = 1, main = "ROC")
plot(performanceLR, col = 2, add = T)
legend(.6,.3,c('Naive Bayes', 'Logistic Regression'), 1:2)

```


## Including Plots

You can also embed plots, for example:


```{r}

revenuemodel <- lm(revenue~budget+popularity+vote_count,data = data)

summary(revenuemodel) #chose those variables because they had the highest r squared
plot(revenuemodel)

revenuemodel2 <- lm(revenue~budget+vote_count,data = data)
summary(revenuemodel2) 
plot(revenuemodel2)

revenuemodel3 <- glm(revenue~budget+popularity+vote_count,data = data)
summary(revenuemodel3)



```

```{r}



```
Random Forest
```{r}
library(randomForest)
library(rpart)

tree <- rpart(revenue~budget+popularity+vote_count, data = data, method = "class")

# build decision forest
forest <- randomForest(revenue~budget+popularity+vote_count, data = data, importance = TRUE, ntree = 1000, na.action=na.roughfix)
# plots regression
# varImpPlot(my_forest)


#evaluate tree and forest on training data
tree.train <- predict(tree, newdata=train, type="class")
forest.train <- predict(forest, newdata=train)

table.traintree <- table(tree.train, train$survived)
table.trainforest <- table(forest.train, train$survived)

#calculate accuracies
accuracy.traintree = sum(diag(table.traintree))/sum(table.traintree) 
accuracy.trainforest = sum(diag(table.trainforest))/sum(table.trainforest) 

cat("Tree training accuracy: ", accuracy.traintree, "\n")
cat("Forest training accuracy: ", accuracy.trainforest, "\n")
```

```{r}
library(randomForest)
library(caret)
library(ggplot2)
library(plotROC)
```
```{r}
#10 folds repeat 3 times
#control <- trainControl(method='repeatedcv', number=10, repeats=3)
control <- trainControl(method='cv', number=10, summaryFunction=twoClassSummary, classProbs=T, savePredictions=T)

# Generate the model:
data$success <- as.factor(data$is_successful)
levels(data$success) <- c("bad", "good")
model <- train(success ~ budget + is_English + release_date + runtime + belongs_to_collection, 
    data=data,
    method='rf',
    trControl=control)
print(model)
```
```{r}
ggplot(model$pred, aes(m=good, d =obs)) + 
  geom_roc(hjust = -0.4, vjust = 1.5) +
  coord_equal() +
  geom_abline(slope=1, intercept=c(0,0)) +
  theme(title=element_text("ROC Curve of Random Forest Algorithm")) +
  labs(x="False Positives", y="True Positives")
```